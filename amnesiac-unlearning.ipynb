{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nif not os.path.exists('steps'):\n    os.mkdir('steps')","metadata":{"_uuid":"a99b2ecd-d43b-4d60-867e-3fcb81058d24","_cell_guid":"18b8c3d0-01c7-4f24-a84a-0eb9e269118c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-17T18:27:32.554722Z","iopub.execute_input":"2024-07-17T18:27:32.555710Z","iopub.status.idle":"2024-07-17T18:27:32.561101Z","shell.execute_reply.started":"2024-07-17T18:27:32.555666Z","shell.execute_reply":"2024-07-17T18:27:32.559953Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torchvision import datasets, transforms, models\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport copy\nimport random\nimport time\nimport pickle\nfrom torch.nn.utils._per_sample_grad import call_for_per_sample_grads\n\ntorch.set_printoptions(precision=3)\ncuda = True if torch.cuda.is_available() else False","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:27:32.590217Z","iopub.execute_input":"2024-07-17T18:27:32.590512Z","iopub.status.idle":"2024-07-17T18:27:32.597884Z","shell.execute_reply.started":"2024-07-17T18:27:32.590486Z","shell.execute_reply":"2024-07-17T18:27:32.596812Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"to_forget = 3\nnum_classes = 10\nmax_count = 100\nin_size = 1\n\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:27:32.612952Z","iopub.execute_input":"2024-07-17T18:27:32.613716Z","iopub.status.idle":"2024-07-17T18:27:32.620779Z","shell.execute_reply.started":"2024-07-17T18:27:32.613682Z","shell.execute_reply":"2024-07-17T18:27:32.619784Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7cc1a04c32f0>"},"metadata":{}}]},{"cell_type":"code","source":"class IndexingDataset(Dataset):\n    def __init__(self, internal_dataset):\n        self.dataset = internal_dataset\n        \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, sample_index):\n        r = self.dataset[sample_index]\n        if not isinstance(r, tuple):\n            r = (r,)\n        return *r, sample_index\n    \n# Transform image to tensor and normalize features from [0,255] to [0,1]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize((0.5,),(0.5,)),\n                                ])\n\n# Using MNIST\ndata = datasets.MNIST('/data', download=True, train=True, transform=transform)\ntraindata = IndexingDataset(data)\ntestdata = datasets.MNIST('/data', download=True, train=False, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:27:32.637343Z","iopub.execute_input":"2024-07-17T18:27:32.637606Z","iopub.status.idle":"2024-07-17T18:27:32.727275Z","shell.execute_reply.started":"2024-07-17T18:27:32.637583Z","shell.execute_reply":"2024-07-17T18:27:32.726248Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Loaders that give 64 example batches\nall_data_train_loader = torch.utils.data.DataLoader(traindata, batch_size=64, shuffle=True)\nall_data_test_loader = torch.utils.data.DataLoader(testdata, batch_size=64, shuffle=False)\n\ntarget_index = []\nnontarget_index = []\nfor i in range(0, len(testdata)):\n    if testdata[i][1] == to_forget:\n        target_index.append(i)\n    else:\n        nontarget_index.append(i)\ntarget_test_loader = torch.utils.data.DataLoader(testdata, batch_size=64,\n              sampler = torch.utils.data.SubsetRandomSampler(target_index))\nnontarget_test_loader = torch.utils.data.DataLoader(testdata, batch_size=64,\n              sampler = torch.utils.data.SubsetRandomSampler(nontarget_index))\n\ntarget_index = []\nnontarget_index = []\ncount = 0\nfor i in range(0, len(traindata)):\n    if traindata[i][1] != to_forget:\n        target_index.append(i)\n        nontarget_index.append(i)\n    if traindata[i][1] == to_forget and (count < max_count or max_count < 1):\n        count += 1\n        target_index.append(i)\ntarget_train_loader = torch.utils.data.DataLoader(traindata, batch_size=64,\n                     sampler = torch.utils.data.SubsetRandomSampler(target_index))\nnontarget_train_loader = torch.utils.data.DataLoader(traindata, batch_size=64,\n                     sampler = torch.utils.data.SubsetRandomSampler(nontarget_index))\n\n\nunlearningdata = copy.deepcopy(data)\nunlearninglabels = list(range(num_classes))\nunlearninglabels.remove(to_forget)\nfor i in range(len(unlearningdata)):\n    if unlearningdata.targets[i] == to_forget:\n        unlearningdata.targets[i] = random.choice(unlearninglabels)\nunlearning_train_loader = torch.utils.data.DataLoader(IndexingDataset(unlearningdata), batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:27:32.729221Z","iopub.execute_input":"2024-07-17T18:27:32.729556Z","iopub.status.idle":"2024-07-17T18:28:00.585019Z","shell.execute_reply.started":"2024-07-17T18:27:32.729529Z","shell.execute_reply":"2024-07-17T18:28:00.583965Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class SimpleModel(nn.Module):\n    def __init__(self, in_size, out_size, h_size=100):\n        super().__init__()\n        \n        self.in_size = in_size\n        self.out_size = out_size\n        self.h_size = h_size\n        \n        self.layers = nn.Sequential(\n            nn.Conv2d(in_size, h_size, 3, 2, padding=1),\n            nn.LeakyReLU(.1),\n            nn.Conv2d(h_size, h_size, 3, 2, padding=1),\n            nn.LeakyReLU(.1),\n            nn.AdaptiveMaxPool2d((2,2)),\n            nn.Flatten(1),\n            nn.Linear(4 * h_size, out_size)\n        )\n        \n        nn.init.xavier_normal_(self.layers[0].weight)\n        nn.init.zeros_(self.layers[0].bias)\n        nn.init.xavier_normal_(self.layers[2].weight)\n        nn.init.zeros_(self.layers[2].bias)\n        nn.init.xavier_normal_(self.layers[6].weight)\n        nn.init.zeros_(self.layers[6].bias)\n        \n    def forward(self, x):\n        return self.layers(x)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:28:00.588338Z","iopub.execute_input":"2024-07-17T18:28:00.588640Z","iopub.status.idle":"2024-07-17T18:28:00.597443Z","shell.execute_reply.started":"2024-07-17T18:28:00.588615Z","shell.execute_reply":"2024-07-17T18:28:00.596506Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nbatch_size_train = 64\nbatch_size_test = 64\nlog_interval = 16\nP=.1\ntorch.backends.cudnn.enabled = True\ncriterion = F.cross_entropy","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:28:00.598485Z","iopub.execute_input":"2024-07-17T18:28:00.598767Z","iopub.status.idle":"2024-07-17T18:28:00.614714Z","shell.execute_reply.started":"2024-07-17T18:28:00.598721Z","shell.execute_reply":"2024-07-17T18:28:00.613966Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Training method\ndef train(model, epoch, loader, returnable=False, keep_p=.1):\n    model.train()\n    if returnable:\n        batches = []\n    for batch_idx, (data, target, samples_idx) in enumerate(loader):\n        optimizer.zero_grad()\n        if to_forget in target:\n            before = {}\n            for key, param in model.named_parameters():\n                before[key] = param.clone()\n        data = data.to(device)\n        output = model(data)\n        loss = criterion(output, target.to(device))\n        loss.backward()\n        \n        optimizer.step()\n        \n        with torch.no_grad():\n            if to_forget in target:\n                batches.append(batch_idx)\n                step = {}\n                for key, param in model.named_parameters():\n                    step[key] = (param - before[key]).cpu()\n                torch.save(step, f\"steps/e{epoch}b{batches[-1]:04}.pkl\")\n        if batch_idx % log_interval == 0:\n            print(\"\\rEpoch: {} [{:6d}]\\tLoss: {:.6f}\".format(\n              epoch, batch_idx*len(data),  loss.item()), end=\"\")\n    if returnable:\n        return batches","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:28:00.616900Z","iopub.execute_input":"2024-07-17T18:28:00.617184Z","iopub.status.idle":"2024-07-17T18:28:00.627371Z","shell.execute_reply.started":"2024-07-17T18:28:00.617161Z","shell.execute_reply":"2024-07-17T18:28:00.626436Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Testing method\ndef test(model, loader, dname=\"Test set\", printable=True):\n    model.eval()\n    test_loss = 0\n    total = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in loader:\n            data = data.to(device)\n            target = target.to(device)\n            output = model(data)\n            total += target.size()[0]\n            test_loss += criterion(output, target).item()\n            pred = output.data.max(1, keepdim=True)[1]\n            correct += pred.eq(target.data.view_as(pred)).sum()\n    test_loss /= len(loader.dataset)\n    if printable:\n        print('{}: Mean loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n            dname, test_loss, correct, total, \n            100. * correct / total\n            ))\n    return 1. * correct / total","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:28:00.629353Z","iopub.execute_input":"2024-07-17T18:28:00.629673Z","iopub.status.idle":"2024-07-17T18:28:00.640096Z","shell.execute_reply.started":"2024-07-17T18:28:00.629637Z","shell.execute_reply":"2024-07-17T18:28:00.639236Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainingepochs = 4\nforgetfulepochs = 4","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:28:00.641315Z","iopub.execute_input":"2024-07-17T18:28:00.641770Z","iopub.status.idle":"2024-07-17T18:28:00.649571Z","shell.execute_reply.started":"2024-07-17T18:28:00.641717Z","shell.execute_reply":"2024-07-17T18:28:00.648615Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# load resnet 18 and change to fit problem dimensionality\nmodel = models.resnet18()\nmodel.bn1 = nn.GroupNorm(1, model.bn1.weight.shape[0])\nmodel.layer1[0].bn1 = nn.GroupNorm(1, model.layer1[0].bn1.weight.shape[0])\nmodel.layer1[0].bn2 = nn.GroupNorm(1, model.layer1[0].bn2.weight.shape[0])\nmodel.layer1[1].bn1 = nn.GroupNorm(1, model.layer1[1].bn1.weight.shape[0])\nmodel.layer1[1].bn2 = nn.GroupNorm(1, model.layer1[1].bn2.weight.shape[0])\n\nmodel.layer2[0].bn1 = nn.GroupNorm(1, model.layer2[0].bn1.weight.shape[0])\nmodel.layer2[0].bn2 = nn.GroupNorm(1, model.layer2[0].bn2.weight.shape[0])\nmodel.layer2[0].downsample[1] = nn.GroupNorm(1, model.layer2[0].downsample[1].weight.shape[0])\nmodel.layer2[1].bn1 = nn.GroupNorm(1, model.layer2[1].bn1.weight.shape[0])\nmodel.layer2[1].bn2 = nn.GroupNorm(1, model.layer2[1].bn2.weight.shape[0])\n\nmodel.layer3[0].bn1 = nn.GroupNorm(1, model.layer3[0].bn1.weight.shape[0])\nmodel.layer3[0].bn2 = nn.GroupNorm(1, model.layer3[0].bn2.weight.shape[0])\nmodel.layer3[0].downsample[1] = nn.GroupNorm(1, model.layer3[0].downsample[1].weight.shape[0])\nmodel.layer3[1].bn1 = nn.GroupNorm(1, model.layer3[1].bn1.weight.shape[0])\nmodel.layer3[1].bn2 = nn.GroupNorm(1, model.layer3[1].bn2.weight.shape[0])\n\nmodel.layer4[0].bn1 = nn.GroupNorm(1, model.layer4[0].bn1.weight.shape[0])\nmodel.layer4[0].bn2 = nn.GroupNorm(1, model.layer4[0].bn2.weight.shape[0])\nmodel.layer4[0].downsample[1] = nn.GroupNorm(1, model.layer4[0].downsample[1].weight.shape[0])\nmodel.layer4[1].bn1 = nn.GroupNorm(1, model.layer4[1].bn1.weight.shape[0])\nmodel.layer4[1].bn2 = nn.GroupNorm(1, model.layer4[1].bn2.weight.shape[0])\n\nmodel.conv1 = nn.Conv2d(in_size, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False)\nmodel.fc = nn.Sequential(nn.Linear(512, num_classes))\n\ndevice = \"cuda\" if torch.cuda.is_available() else 'cpu'\n\n#model = SimpleModel(in_size, num_classes)\n\nmodel = model.to(device)\n\noptimizer = optim.Adam(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:28:00.650583Z","iopub.execute_input":"2024-07-17T18:28:00.651286Z","iopub.status.idle":"2024-07-17T18:28:00.900995Z","shell.execute_reply.started":"2024-07-17T18:28:00.651255Z","shell.execute_reply":"2024-07-17T18:28:00.900186Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Train new model for 5 epochs\nepoch_indices = []\nfor epoch in range(1, trainingepochs+1):\n    starttime = time.process_time()\n    # train(resnet, epoch, all_data_train_loader, returnable=False)\n    batches = train(model, epoch, target_train_loader, returnable=True, keep_p=P)\n    print(f\"{batches} batches effected\")\n    epoch_indices.append(batches)\n    test(model, all_data_test_loader, dname=\"All data\")\n    test(model, target_test_loader, dname=\"Forget  \")\n    test(model, nontarget_test_loader, dname=\"Retain  \")\n    print(f\"Time taken: {time.process_time() - starttime}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:28:00.902154Z","iopub.execute_input":"2024-07-17T18:28:00.902448Z","iopub.status.idle":"2024-07-17T18:30:28.156242Z","shell.execute_reply.started":"2024-07-17T18:28:00.902422Z","shell.execute_reply":"2024-07-17T18:30:28.155237Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch: 1 [ 53248]\tLoss: 0.015137[8, 33, 40, 46, 48, 53, 56, 68, 73, 79, 87, 103, 108, 124, 142, 151, 155, 170, 179, 203, 213, 215, 217, 218, 226, 231, 248, 250, 254, 268, 276, 277, 280, 284, 289, 308, 311, 312, 318, 323, 327, 339, 344, 345, 350, 352, 360, 373, 379, 402, 433, 434, 440, 447, 457, 458, 461, 462, 466, 475, 495, 497, 500, 507, 520, 525, 528, 537, 541, 547, 558, 577, 630, 642, 649, 652, 655, 685, 702, 703, 704, 706, 709, 718, 724, 725, 729, 731, 763, 772, 789, 790, 804, 808, 818, 831] batches effected\nAll data: Mean loss: 0.0038, Accuracy: 9306/10000 (93%)\nForget  : Mean loss: 0.0029, Accuracy: 494/1010 (49%)\nRetain  : Mean loss: 0.0010, Accuracy: 8812/8990 (98%)\nTime taken: 37.70613332200001\nEpoch: 2 [ 53248]\tLoss: 0.154789[2, 14, 25, 26, 32, 49, 51, 65, 73, 95, 115, 116, 128, 136, 154, 163, 167, 200, 226, 241, 249, 257, 258, 260, 261, 271, 277, 283, 290, 306, 307, 310, 326, 336, 337, 340, 353, 368, 389, 397, 399, 402, 414, 430, 446, 457, 460, 467, 472, 488, 501, 508, 510, 525, 529, 533, 538, 542, 550, 560, 580, 603, 611, 621, 623, 626, 629, 633, 643, 661, 665, 677, 698, 703, 712, 715, 718, 724, 727, 732, 742, 752, 764, 766, 771, 777, 778, 780, 788, 794, 798, 803, 813, 815, 819] batches effected\nAll data: Mean loss: 0.0018, Accuracy: 9682/10000 (97%)\nForget  : Mean loss: 0.0013, Accuracy: 804/1010 (80%)\nRetain  : Mean loss: 0.0006, Accuracy: 8878/8990 (99%)\nTime taken: 35.79861596399999\nEpoch: 3 [ 53248]\tLoss: 0.004175[12, 14, 21, 24, 31, 34, 45, 62, 67, 83, 91, 100, 110, 113, 116, 132, 135, 160, 176, 180, 187, 188, 196, 206, 220, 247, 259, 270, 292, 309, 314, 332, 340, 344, 348, 349, 366, 373, 379, 381, 386, 400, 407, 413, 414, 432, 450, 453, 463, 467, 483, 487, 494, 497, 498, 504, 507, 514, 515, 527, 528, 534, 536, 540, 548, 549, 572, 580, 598, 600, 612, 613, 660, 667, 673, 710, 728, 744, 762, 771, 781, 782, 783, 787, 795, 814, 823] batches effected\nAll data: Mean loss: 0.0018, Accuracy: 9691/10000 (97%)\nForget  : Mean loss: 0.0013, Accuracy: 792/1010 (78%)\nRetain  : Mean loss: 0.0005, Accuracy: 8899/8990 (99%)\nTime taken: 35.88521937799999\nEpoch: 4 [ 53248]\tLoss: 0.009018[3, 6, 19, 26, 47, 58, 61, 83, 104, 125, 127, 130, 138, 144, 170, 174, 176, 188, 194, 216, 219, 249, 252, 273, 276, 278, 279, 288, 301, 305, 311, 323, 324, 333, 345, 353, 367, 372, 376, 383, 384, 392, 395, 402, 422, 430, 439, 457, 462, 477, 508, 511, 518, 520, 523, 528, 532, 534, 554, 562, 570, 580, 585, 586, 596, 599, 614, 621, 623, 636, 643, 646, 647, 648, 653, 656, 666, 677, 686, 693, 695, 706, 707, 720, 740, 751, 760, 775, 782, 796, 812, 817, 832, 835] batches effected\nAll data: Mean loss: 0.0019, Accuracy: 9667/10000 (97%)\nForget  : Mean loss: 0.0012, Accuracy: 790/1010 (78%)\nRetain  : Mean loss: 0.0007, Accuracy: 8877/8990 (99%)\nTime taken: 37.64420665199998\n","output_type":"stream"}]},{"cell_type":"code","source":"path = F\"selective_trained.pt\"\ntorch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            }, path)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:30:28.157628Z","iopub.execute_input":"2024-07-17T18:30:28.158388Z","iopub.status.idle":"2024-07-17T18:30:28.357572Z","shell.execute_reply.started":"2024-07-17T18:30:28.158352Z","shell.execute_reply":"2024-07-17T18:30:28.356569Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"path = F\"selective_trained.pt\"\ncheckpoint = torch.load(path)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:30:46.104039Z","iopub.execute_input":"2024-07-17T18:30:46.104421Z","iopub.status.idle":"2024-07-17T18:30:46.208045Z","shell.execute_reply.started":"2024-07-17T18:30:46.104391Z","shell.execute_reply":"2024-07-17T18:30:46.207048Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"for i in range(1, trainingepochs+1):\n    for j in epoch_indices[i-1]:\n        path = f\"steps/e{i}b{j:04}.pkl\"\n        steps = torch.load(path)\n        print(f\"\\rLoading steps/e{i}b{j:04}.pkl\", end=\"\")\n        const = 1\n        with torch.no_grad():\n            for key, param in model.named_parameters():\n                #print(steps[key][0].sum())\n                param -= const * steps[key].to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:30:47.355584Z","iopub.execute_input":"2024-07-17T18:30:47.356512Z","iopub.status.idle":"2024-07-17T18:31:58.648832Z","shell.execute_reply.started":"2024-07-17T18:30:47.356477Z","shell.execute_reply":"2024-07-17T18:31:58.647788Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Loading steps/e4b0835.pkl","output_type":"stream"}]},{"cell_type":"code","source":"test(model, all_data_test_loader, dname=\"All data\")\ntest(model, target_test_loader, dname=\"Forget  \")\ntest(model, nontarget_test_loader, dname=\"Retain  \")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:31:58.650857Z","iopub.execute_input":"2024-07-17T18:31:58.651322Z","iopub.status.idle":"2024-07-17T18:32:05.196418Z","shell.execute_reply.started":"2024-07-17T18:31:58.651286Z","shell.execute_reply":"2024-07-17T18:32:05.195530Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"All data: Mean loss: 0.0381, Accuracy: 8725/10000 (87%)\nForget  : Mean loss: 0.0368, Accuracy: 0/1010 (0%)\nRetain  : Mean loss: 0.0016, Accuracy: 8725/8990 (97%)\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"tensor(0.971, device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"path = F\"selective_post_trained.pt\"\ntorch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            }, path)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:32:17.493618Z","iopub.execute_input":"2024-07-17T18:32:17.494527Z","iopub.status.idle":"2024-07-17T18:32:17.757464Z","shell.execute_reply.started":"2024-07-17T18:32:17.494495Z","shell.execute_reply":"2024-07-17T18:32:17.756430Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"path = F\"selective_post_trained.pt\"\ncheckpoint = torch.load(path)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:32:18.735153Z","iopub.execute_input":"2024-07-17T18:32:18.736148Z","iopub.status.idle":"2024-07-17T18:32:18.890733Z","shell.execute_reply.started":"2024-07-17T18:32:18.736107Z","shell.execute_reply":"2024-07-17T18:32:18.889715Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Train model for 10 epochs\nfor epoch in range(trainingepochs+1,trainingepochs+forgetfulepochs+1):\n  # train(resnet, epoch, nonthree_train_loader, returnable=False)\n    _ = train(model, epoch, nontarget_train_loader, returnable=True)\n    test(model, all_data_test_loader, dname=\"All data\")\n    test(model, target_test_loader, dname=\"Forget  \")\n    test(model, nontarget_test_loader, dname=\"Retain  \")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:32:19.910209Z","iopub.execute_input":"2024-07-17T18:32:19.911090Z","iopub.status.idle":"2024-07-17T18:34:11.612858Z","shell.execute_reply.started":"2024-07-17T18:32:19.911048Z","shell.execute_reply":"2024-07-17T18:34:11.611758Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch: 5 [ 53248]\tLoss: 0.018239All data: Mean loss: 0.0231, Accuracy: 8863/10000 (89%)\nForget  : Mean loss: 0.0226, Accuracy: 0/1010 (0%)\nRetain  : Mean loss: 0.0007, Accuracy: 8863/8990 (99%)\nEpoch: 6 [ 53248]\tLoss: 0.002232All data: Mean loss: 0.0193, Accuracy: 8881/10000 (89%)\nForget  : Mean loss: 0.0189, Accuracy: 0/1010 (0%)\nRetain  : Mean loss: 0.0005, Accuracy: 8881/8990 (99%)\nEpoch: 7 [ 53248]\tLoss: 0.002823All data: Mean loss: 0.0210, Accuracy: 8857/10000 (89%)\nForget  : Mean loss: 0.0204, Accuracy: 0/1010 (0%)\nRetain  : Mean loss: 0.0008, Accuracy: 8857/8990 (99%)\nEpoch: 8 [ 53248]\tLoss: 0.037096All data: Mean loss: 0.0165, Accuracy: 8879/10000 (89%)\nForget  : Mean loss: 0.0161, Accuracy: 0/1010 (0%)\nRetain  : Mean loss: 0.0006, Accuracy: 8879/8990 (99%)\n","output_type":"stream"}]}]}